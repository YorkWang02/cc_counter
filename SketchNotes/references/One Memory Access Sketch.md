# 0.摘要
Sketch是一种在真实网络中广泛用于按流量测量的概率数据结构。Sketch用于按流量测量的关键指标是它们的内存使用、准确性和速度。虽然有多种Sketch，但在固定内存大小的情况下，它们不能同时实现高准确性和高速度。为了解决这个问题，我们提出了一种新的Sketch，即OM（One Memory）Sketch。它的准确性比现有技术高得多，并且在每次插入或查询时几乎只需要一次内存访问和一次哈希计算。我们OM Sketch的关键方法是利用基于分层结构的字约束和指纹技术。基于真实IP跟踪的大量实验表明，与著名的CM Sketch [1]相比，准确性提高了多达10.64倍，速度提高了多达2.50倍。所有相关源代码已在GitHub [2]上发布。

# 1.引言
## A. 背景和动机
随着现代社会进入大型网络数据时代，一个根本性问题是如何高效地监视和管理网络，即所谓的网络管理。在这个重大问题中，最重要的方面之一是按流量测量，这是指估计在一段时间内每个流的数据包数量。一个流通过从数据包头或数据包内容中提取的流ID来唯一标识。例如，我们有按源流、按目的地流、由五元组组成的TCP流，甚至按其数据包内容分类的流。按流量测量具有许多重要的应用。例如，通过估计每个TCP流中的数据包数量，ISP可以制定适当的流量路由策略以减轻网络拥塞[3]。通过估计从每个源IP发送的SYN数据包的数量，网络管理员可以及时检测到SYN洪泛攻击[4]，[5]。在SDN网络中，按流量测量可以帮助网络管理员智能地分配网络带宽到不同的路径上。入侵检测系统可以利用按流量测量的信息来查找重量级数据[6]，以及监视某些路径上发生的重大变化[7]，[8]。由于按流量测量在现代网络管理中扮演着重要的角色，因此已经提出了许多算法[9]–[11]。
一种有效的按流量测量解决方案基于概率数据结构称为Sketch[12] - [14]，这是一个二维数组。Sketch有两个主要操作：插入和查询。在插入期间，它可以紧凑地记录有关流量大小的信息。在查询期间，给定流ID，它报告相应的流量大小。Sketch的关键机制称为计数器共享，这意味着接受哈希冲突，并让两个或多个流共享相同的计数器。在传统的Sketch中，计数器的大小需要特别定制，以容纳最大的流量大小。然而，现实网络中的流量大小分布是高度倾斜的[15]，[16]。换句话说，少数几个流量的大小很大（例如，> 40000），而大多数流量的大小很小（例如，< 16）（分别称为大象流和小鼠流）。因此，在传统Sketch的大多数计数器中，高位比特是浪费的。这种内存效率低下必然会降低准确性。此外，传统的Sketch无法完全跟上网络流的快速速度，因为它每次插入或查询需要三个或更多的内存访问和哈希计算。本文的设计目标是设计一种新的Sketch，它同时实现高准确性、高插入速度和高查询速度。

## B. 先前的研究
有三种典型的Sketch广泛用于按流量测量：CM Sketch [1]，CU Sketch [17]和Count Sketch [18]。CM Sketch由d个数组组成：A1，A2，...，Ad，每个数组由w个计数器组成，并与哈希函数hi（。）（1≤hi（。）≤w，1≤i≤d）对应。插入流e时，CM Sketch首先计算d个哈希函数并定位d个计数器：A1 [h1（e）]，A2 [h2（e）]，...，Ad [hd（e）]。然后它递增所有d个哈希计数器。查询流e时，CM Sketch报告d个哈希计数器中的最小值。CU Sketch [17]相比于CM Sketch，进行了轻微但有效的修改，即保守更新。在插入过程中，CU Sketch仅增加d个哈希计数器中最小的计数器（可能有两个或更多个最小计数器），而查询过程保持不变。Count Sketch [18]与CM Sketch类似，只是每个数组使用额外的哈希函数来平滑意外错误。在这些Sketch中，CU Sketch在准确性和速度方面都表现最佳。不幸的是，正如第I-A节中提到的那样，所有上述Sketch在内存效率，多个内存访问和每个插入或查询的多个哈希计算方面都存在问题。换句话说，它们都有以下缺点：1）使用小内存时准确性较差；2）插入和查询速度受限。

## C. 提出的解决方案
本文提出了一种新型Sketch，称为OM（One Memory）Sketch。我们OM Sketch的关键思想是利用基于分层结构的字约束和指纹技术，同时实现高准确性和高速度。我们将OM Sketch组织成一个分层结构，其中较高层次拥有较少的内存。具体而言，小计数器大小的较低层主要记录小鼠流的信息，而具有相对较大计数器大小的较高层主要记录大象流的信息。这样，内存效率得到了显著提高。当一个或多个计数器在较低层次上溢出时，我们使用较高层次记录其溢出数量。我们称之为分层计数器共享。此外，我们还有以下两个关键观察结果：1）较低层次的计数器大小自然较小（例如，4位），这意味着一个机器字可以包含足够的计数器。2）现实网络中的大象流非常稀少，这意味着插入一个任意流量访问第二层或更高层的概率非常低（例如，1/20）。因此，我们可以将相应的哈希计数器限制在一个或多个机器字内，并实现每次插入接近一个内存访问。我们称之为字加速。为了加速哈希计算，我们利用哈希位技术[19]在每层中通过64位哈希值定位一个或多个机器字内的多个哈希计数器。我们进一步通过使用指纹检查技术提高OM Sketch的准确性：我们在较低层的相应机器字中记录溢出流的指纹，以便在查询期间将其与非溢出流区分开来。

## D. 主要贡献
1）我们提出了一种新型的Sketch，称为OM Sketch，其中包含三种关键技术：分层计数器共享，字加速和指纹检查。
2）我们在真实IP跟踪上进行了广泛的实验，结果表明，与现有技术相比，我们的OM Sketch在准确性和速度方面都具有显著的优势。

# 2.相关工作
考虑到流量测量的重要性日益增长，已经提出了许多解决方案来解决这个问题。这些解决方案分为三大类：Sketches，计数器变体和Bloom过滤器变体。
Sketches [15]：CM、CU和Count Sketch已经在第I-B节中介绍过了。
计数器变体：计数器编织[20]和随机计数器共享[11]是计数器变体的两种典型算法。在计数器编织中，每个流的测量需要进行后处理。具体而言，在查询某个特定的流之前，必须事先获取所有不同流的信息。因此，查询速度显著降低。随机计数器共享在插入过程中随机增加d个哈希计数器之一，并在查询过程中报告所有d个哈希计数器之和减去噪声。这种算法为了速度而牺牲了准确性。
Bloom过滤器变体：这种解决方案基于Bloom过滤器[21]，它可以告诉我们一个流是否属于一个集合，但不能报告流的频率。计数Bloom过滤器（CBF）[22]可以估计流的频率。CBF的机制类似于CM Sketch，只是CBF只有一个数组。基于CBF，还提出了一些其他存储流频率的变体：Spectral Bloom Filter（SBF）[23]和Dynamic Count Filter（DCF）[24]。然而，所有这些算法都需要多次内存访问和哈希计算才能进行每次插入或查询，这会降低速度。
总之，虽然在这个领域提出了各种各样的解决方案，但是没有任何一种现有算法能够同时实现高准确性和高速度。

# 3. OM Sketch算法
在本节中，我们首先阐明为什么我们主要关注具有两层的OM Sketch。然后，我们一一介绍了OM Sketch的三个关键技术：分层计数共享、单词加速和指纹检查。通过利用这三种技术，我们的OM Sketch可以平均每次插入或查询实现接近一次内存访问和一次哈希计算（在最坏情况下，需要三次内存访问和两次哈希计算），同时显着提高精度。
A. 多层OM Sketch
多层OM Sketch有𝛾层：𝐿𝑖（1≤i≤𝛾），以便在细粒度上进行每流测量。每一层𝐿𝑖都有自己的计数器大小𝛿𝑖和计数器数量𝑤𝑖。当插入流𝑒时，我们首先更新层𝐿1。如果在层𝐿1中有一个或多个计数器溢出，我们使用层𝐿2记录相应的溢出数量。此过程继续递归，直到某个层没有溢出。具有大𝛾（例如3或更多）的OM Sketch可以实现高内存效率，但在最坏情况下至少会产生𝛾次内存访问。如果𝛾相对较大（例如3或更多），OM Sketch在某些情况下可能无法跟上线路速度。此外，实验结果表明，与三层或更多层的OM Sketch相比，具有两层的OM Sketch仅略微提高了精度。因此，在大多数情况下，我们将𝛾设置为2，以缓解OM Sketch在最坏情况下的速度下降。在本节的剩余部分，我们将详细介绍具有两层的OM Sketch。注意，多层OM Sketch的机制与具有两层的OM Sketch几乎相同。

1）层次共享计数器
数据结构：如图1所示，我们的OM Sketch（为了方便，我们在本文中仅将双层OM Sketch称为OM Sketch）由两个分层组成：低层和高层。低层Ll由wl个计数器组成，每个计数器有δl位（取值范围为0到2^δl-1），高层Lh由wh个计数器组成，每个计数器有δh位（取值范围为0到2^δh-1）。我们有δl<δh，并且稍后将提到原因。我们将表示低层或高层的第i个计数器为Ll[i]或Lh[i]。低层与dl个独立的哈希函数hi_l（1≤i≤dl）相关联，其输出在区间[1，wl]内均匀分布，而高层与dh个独立的哈希函数hi_h（1≤i≤dh）相关联，其输出在区间[1，wh]内均匀分布。

我们的OM Sketch具有以下两个主要操作：插入和查询。最初，两个层的所有计数器都设置为零。

插入：当插入一个流量𝑒时，我们首先使用流ID计算出𝑑𝑙个哈希函数ℎ1𝑙(𝑒), ℎ2𝑙(𝑒), ..., ℎ𝑑𝑙𝑙(𝑒)(1⩽ℎ𝑙(.)⩽𝑤𝑙)，并定位到低层𝐿𝑙的𝑑𝑙个哈希计数器𝐿𝑙[ℎ1𝑙(𝑒)], 𝐿𝑙[ℎ2𝑙(𝑒)], ..., 𝐿𝑙[ℎ𝑑𝑙𝑙(𝑒)]。然后我们将最小的计数器加1。当在低层发生溢出时，我们观察到：流𝑒必须同时导致其对应的𝑑𝑙个哈希计数器溢出。对于低层的溢出，有两种情况：1）如果𝑑𝑙个哈希计数器中没有发生共享，则这些计数器始终保持相同的值并同时溢出。2）如果在𝑑𝑙个哈希计数器中发生计数器共享，则这些哈希计数器的值可能不同。增加最小计数器的方法总是倾向于缩小值的差异。只有当𝑑𝑙个哈希计数器都达到2𝛿𝑙−1的值时，𝑑𝑙个哈希计数器才有机会溢出。因此，这些𝑑𝑙个哈希计数器将始终同时溢出。因此，我们只需使用流ID作为𝑑ℎ个哈希函数ℎ𝑖ℎ(.)的键（1⩽𝑖 ⩽𝑑ℎ）来定位到高层的𝑑ℎ个哈希计数器𝐿ℎ[ℎ1ℎ(𝑒)], 𝐿ℎ[ℎ2ℎ(𝑒)], ..., 𝐿ℎ[ℎ𝑑ℎ𝑖(𝑒)]。然后，我们在高层增加最小的𝑑ℎ个哈希计数器，并将低层的所有𝑑𝑙个哈希计数器都设置为零。这样，高层记录了该流的溢出次数。

查询：查询流𝑒时，首先计算𝑑𝑙个哈希函数ℎ1𝑙(𝑒), ℎ2𝑙(𝑒), ..., ℎ𝑑𝑙𝑙(𝑒)(1⩽ℎ𝑙(.)⩽𝑤𝑙)，并定位在低层的𝑑𝑙个哈希计数器𝐿𝑙[ℎ1𝑙(𝑒)], 𝐿𝑙[ℎ2𝑙(𝑒)], ..., 𝐿𝑙[ℎ𝑑𝑙𝑙(𝑒)]。然后获取低层的𝑑𝑙个哈希计数器中最小的计数器的值，并用𝑉𝑙表示。类似地，我们可以使用流ID作为键计算𝑑ℎ个哈希函数，并获取高层的𝑑ℎ个哈希计数器中最小的计数器的值。我们将其表示为𝑉ℎ。然后我们报告𝑉𝑙+𝑉ℎ×2𝛿𝑙作为流𝑒的估计大小。

正如在第I-A节中提到的那样，在真实网络中流大小分布高度不均匀。大流经常被认为更为重要，计数器大小应该特别针对CM [1]、CU [17]和Count [18]草图中的大流进行定制。在这种情况下，常规草图的统一计数器对于小流来说太大了，无法“填满”。因此，大多数计数器中高阶位的浪费导致了内存效率和准确性的下降。幸运的是，使用分层计数器共享技术的两层OM草图正好可以解决这个问题。我们使用低层有效地记录小流的信息，以减轻内存浪费，并使用高层仅记录大流的信息，以提高准确性。因此，𝛿𝑙设置为一个小值（例如4位），以仅容纳小流的大小。𝛿ℎ需要设置为相对较大的值（例如16位），以容纳大流的大小。

2）字约束：
字约束技术中，我们将低层的计数器大小𝛿𝑙设为4位，并将低层的𝑑𝑙个散列计数器限制在一个机器字（machine word）中。我们称这个机器字为此流的散列字。设一个机器字有W位。此外，低层𝐿𝑙与𝑑𝑙+1个独立散列函数相关联。第一个散列函数用于定位低层中的一个机器字，而另外的𝑑𝑙个散列函数则用于定位该机器字中的𝑑𝑙个计数器。对于高层，我们将𝑑ℎ个散列计数器限制在若干（例如2个）机器字内，并在这些机器字上均匀分散这些计数器，因为𝛿ℎ（例如16位）应该大于𝛿𝑙（例如4位）。具体来说，高层𝐿ℎ与𝑑ℎ+2个独立散列函数相关联。前两个散列函数分别定位高层中的两个机器字，而另外的𝑑ℎ个散列函数则用于定位这两个机器字内的𝑑ℎ个计数器。我们将低层中的第𝑖个机器字表示为𝐿𝑤𝑙[𝑖]，而表示该字中的第𝑗个计数器为𝐿𝑤𝑙[𝑖][𝑗]。类似地，我们有𝐿𝑤ℎ[𝑖]和𝐿𝑤ℎ[𝑖][𝑗]。在现代CPU中，机器字通常是64位宽的。在GPU体系结构中，机器字的大小要大得多，因为GPU可以在一次存储器访问中读/写1024位[25]。因此，一个机器字可以包含足够的计数器，可以由𝑑𝑙或𝑑ℎ/2个散列函数进行散列。此外，由于实际网络中的流大小分布非常倾斜[15]，[16]，每次插入访问高层的概率非常小（例如1/20）。因此，每次插入的平均内存访问次数接近1（例如1+1/20×2=1.1）。

Hash Bit: 此外，我们采用了文献[19]中的哈希位技术来减少哈希计算的数量。我们将一个64位（在实际的每流测量任务中，64位足够了）哈希值分割成多个位数组，以定位一个或多个机器字和相应机器字中的𝑑𝑙或𝑑ℎ偏移量。换句话说，我们使用一个64位哈希函数作为低层的𝑑𝑙+1个哈希函数或高层的𝑑ℎ+2个哈希函数。另外，假设访问高层的概率大约为1/20。在这种情况下，每次插入的平均哈希计算次数接近1（1+1/20∗1=1.05）。

3）指纹检查：
仅仅基于上述两种技术，我们的OM Sketch不能达到满意的准确性和查询速度。原因是，小流量总是需要查询高层并且容易得到一个非零的 $V_h$，这占据了最终估计结果的很大一部分。因此，小流量的估计大小通常被大大高估，并且查询速度也受到严格限制。为了解决这个问题，我们提出了指纹检查技术。

Fingerprint和flag：如图2所示，低层的每个字都被分为三个部分：𝜌位指纹、1位标记、计数部分。所有三个部分最初都设置为零。低层一个字中的𝑑𝑙个哈希计数器将从计数部分中选择，计数部分包括𝜆𝛿𝑙位计数器。参数需要满足W=𝜌+1+𝜆×𝛿𝑙。请注意，在以下论文中，𝑤𝑙仅表示低层所有字的计数部分中的计数器数量。为了方便起见，我们使用𝐿𝑤𝑙[𝑖].𝑓𝑝，𝐿𝑤𝑙[𝑖].𝑓𝑙𝑎𝑔，𝐿𝑤𝑙[𝑖].𝑐𝑜𝑢𝑛𝑡表示字𝐿𝑤𝑙[𝑖]的三个部分。对于任意流𝑒，让𝑜𝑖𝑙(𝑒)(1⩽𝑖⩽𝑑𝑙)表示其在低层相应计数部分中哈希计数器的偏移量。同样，我们有𝑜𝑖ℎ(𝑒)(1⩽𝑖⩽𝑑ℎ)。这个流的指纹𝑓𝑝(𝑒)(𝜌位)是通过几个逻辑操作从𝑑𝑙偏移中导出的。请注意，如果(𝐿𝑤𝑙[𝑖].𝑓𝑝 & 𝑓𝑝(𝑒)) ≠ 𝐿𝑤𝑙[𝑖].𝑓𝑝，则称𝑓𝑝(𝑒) ⊈ 𝐿𝑤𝑙[𝑖].𝑓𝑝。

插入操作：插入过程如算法1所示。如果在低层不会发生溢出，我们只需增加最小的哈希计数器。如果发生了溢出，我们首先将所有d_l个哈希计数器设置为零，然后检查此流是否是在此哈希词中的第一个溢出的流。如果不是，我们将L_wl [i] .flag设置为1。因此，L_wl [i] .flag指示了在L_wl [i]中哈希的溢出流的数量是否超过了1个。第7行通过逻辑OR运算将f_p（e）记录在L_wl [i] .f_p中。我们看到L_wl [i] .f_p是所有溢出的哈希在L_wl [i]词中的指纹的逻辑OR结果。第8行增加了高层中最小的哈希计数器。

Query: 查询的过程如下所示。首先，我们获取低层中最小散列计数器的值。然后我们检查 𝐿𝑤𝑙[𝑖].𝑓𝑙𝑎𝑔 是否为 1。1）如果是，散列在此字中的溢出流的数量必须超过一个。因此，我们需要进一步检查是否 𝑓𝑝(𝑒) ⊈ 𝐿𝑤𝑙[𝑖].𝑓𝑝。如果 𝑓𝑝(𝑒) ⊈ 𝐿𝑤𝑙[𝑖].𝑓𝑝，则此流没有溢出。我们只返回 𝑉𝑙。2）如果不是，则此字中散列的溢出流的数量必须为一或零。我们需要进一步检查是否 𝑓𝑝(𝑒) ≠ 𝐿𝑤𝑙[𝑖].𝑓𝑝。如果 𝑓𝑝(𝑒) ≠ 𝐿𝑤𝑙[𝑖].𝑓𝑝，则此流没有溢出。我们只返回 𝑉𝑙。3）在其余的情况下，这个流很有可能溢出。我们需要查询高层并获取 𝑉ℎ。然后，我们返回 𝑉𝑙+𝑉ℎ×2𝛿𝑙 作为估计的流大小。





# 5. 结论
Sketch是一种在per-flow测量领域中特别有用的数据结构。本文提出了一种新颖的sketch，即OM sketch，它在每次插入或查询时实现了接近一个内存访问和一个哈希计算的速度，并同时实现了高精度。我们的OM sketch包括三个关键技术：分层计数共享，字加速和指纹检查。实验结果表明，与现有技术相比，我们的OM sketch在速度和准确性方面都有显著的性能提升。我们相信，我们的OM sketch可以很好地应用于per-flow测量领域。我们在Github上公布了所有相关的源代码[2]。
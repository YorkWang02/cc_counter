# 0.摘要
近似流处理算法，如Count-Min sketch、Space-Saving等，支持数据库、存储系统、网络等领域的众多应用。然而，实际数据流中的不平衡分布对现有算法提出了巨大挑战。为了增强这些算法，我们提出了一个元框架，称为Cold Filter（CF），以实现更快速、更准确的流处理。
与现有主要关注热门项的过滤器不同，我们的过滤器在第一阶段捕捉冷门项，第二阶段捕捉热门项。此外，现有的过滤器需要双向通信-在两个阶段之间频繁交换；与之相反，我们的过滤器是单向的-每个项最多进入一个阶段。我们的过滤器可以准确地估计冷门和热门项，具有通用性，适用于许多流处理任务。为了说明我们的过滤器的好处，我们将其部署在三个典型的流处理任务上，并实验结果显示速度提高了最多4.7倍，准确度提高了最多51倍。所有源代码都可以在Github上公开获取[1]。

# 1 引言
在许多大数据场景中，数据以高速数据流的形式出现[2-5]，例如电话呼叫、视频、传感器数据、网络流量、网络点击和网络爬取。这种数据流通常是单遍处理[5-8]。在许多应用中，需要在数据流的每个时间窗口中获取一些统计信息，例如项频率[9]、前k个热门项[10,11]、重要更改[12]和分位数[13]。然而，使用哈希表等精确统计数据的计算通常是不切实际的，因为存储整个数据流所需的空间和时间成本太高。因此，概率数据结构[11,14-25]在近似处理中变得更加流行。
数据流到达的速度和大小共同使得近似流处理具有挑战性。首先，处理的内存使用量应该足够小，以适应有限大小和昂贵的SRAM（静态RAM，例如CPU缓存），以实现高处理速度。其次，必须在单次遍历中处理数据，这高度限制了处理必须进行的速度。最后，为保证应用程序的性能，准确性应尽可能高。

真实数据流的特征：根据我们对真实数据集的测试和文献[5,15]，实际上，出现在真实数据流中的项通常服从不平衡分布，例如Zipf [26]或幂律[27]。这意味着大多数项都不受欢迎（称为冷门项），而少数项非常受欢迎（称为热门项）。我们将这样的数据流称为偏斜数据流。这些特征对流处理任务构成了巨大挑战。流处理任务可以分为两种：第一种需要准确记录热门和冷门项，例如估算项频率和项频率分布。第二种需要准确记录只有热门项，例如前k个和重要更改。接下来，我们展示了三个关键流处理任务的例子。
估算项频率：估算每个项的频率是数据流中最经典的任务之一[9,15]。两个典型的解决方案是Count-Min sketch [9]和CM-CU sketch [28]。它们都使用固定大小的多个计数器来存储项的频率。如果每个计数器都很小，那么超出计数器最大值的热门项的频率就不能被记录。这在实践中几乎不可接受，因为热门项在实践中通常被认为更重要。如果每个计数器足够大，以容纳最大频率，则大多数计数器的高位将被浪费，因为真实数据流中热门项比冷门项少得多。

查找前k个热门项：前k个问题在各个领域中都很重要，包括数据流[9-11,15]。由于我们无法存储所有输入项，每个项只能处理一次，最先进的解决方案Space-Saving [10]在称为Stream-Summary的数据结构中近似地保留前k个项。对于不在Stream-Summary中的输入项，Space-Saving假定它略大于Stream-Summary中的最小项，并交换它们以实现快速处理速度。大多数项都是冷门项，每个冷门项都会进入Stream-Summary，并可能保留或被驱逐。由冷门项引起的频繁交换应该避免，会降低前k个结果的准确性。
检测重要更改：一些项的频率可能在短时间内发生显著变化。检测这些项对于搜索引擎[29]和安全[12,30]很重要。最先进的解决方案是FlowRadar [30]，它依赖于可逆布隆查找表（IBLT）[31]。它使用IBLT来近似监视所有输入项及其频率在两个相邻的时间窗口中的情况，然后比较它们的频率并得出结论。如果有足够的内存记录每个项，FlowRadar可以实现高准确性，但在许多情况下这是不可行的。实际上，在每个时间窗口中，有大量的冷门项，这些项不必被记录，而且比热门项占用更多的内存。
简而言之，偏斜数据流的特征使得最先进的算法很难表现良好或需要大量资源。为了解决这个挑战，提出了几种在数据流上进行过滤的算法，例如增强型sketch [5]、去除冷门项的sketch [32]等。它们使用类似CPU缓存的机制：所有项首先在第一阶段中进行处理，然后将冷门项交换到第二阶段。优点是热门项可能具有较少的内存访问。事实上，准确捕捉热门项很困难，因为所有热门项最初都是冷门项，并存储在第二阶段中，然后才变为热门项。因此，现有算法需要使用双向通信，频繁交换和两个阶段之间的通信。使用双向通信的现有过滤器具有以下缺点：1）它们在第一阶段中使用堆或表，因此通常需要许多内存访问来处理每个项；2）第一阶段只能捕捉少数热门项（例如增强sketch中的32个热门项），因为更多热门项需要更多的内存访问；3）它们使得难以执行流水线并行。我们的设计目标是设计一种依赖于单向通信的过滤器，旨在以更高的处理速度准确估计热门项和冷门项。
我们的Cold Filter (CF)，如图1所示，使用具有小计数器的两层sketch来准确记录冷门项的频率。如果所有哈希计数器溢出，CF将将输入项报告为热门项（单向通信），并将其发送到现有的流处理算法（例如CM-CU sketch，Space-Saving和FlowRadar）。我们可以以不同的方式将CF与不同的现有算法组合，从而获得巨大的好处，因此我们将其称为元框架。CF通过有限的修改与现有算法配合使用，但显著提高了准确性。第一阶段仅使用小计数器来存储冷门项的频率，因此内存效率高。通过过滤大量的冷门项，第二阶段集中于热门项，因此可以实现高准确性。为了提高处理速度，我们利用一系列技术，1）聚合和报告（包括SIMD并行性），2）一次内存访问和3）多核并行，使这三个关键任务能够实现更高的处理速度。由于我们的Cold Filter可以准确记录冷门项和热门项的信息，因此适用于大多数流处理任务。


# 2.相关工作
sketch在数据流中估计项频率方面得到广泛应用。最常用的sketch是Count-Min sketch [9]。它依赖于d个数组A1…Ad，每个数组都由w个计数器组成。在Count-Min sketch中，有d个哈希函数h1…hd。当插入频率为f的项e时，Count-Min sketch会将所有d个哈希计数器A1[h1(e)]…Ad[hd(e)]增加f。当查询项e'时，它将这个项的估计频率报告为d个哈希计数器的最小值，即min1⩽i⩽d{Ai[hi(e')]}。另一个算法，CM-CU sketch [28]，实现了更高的准确性。唯一的区别在于CM-CU只增加d个哈希计数器中最小的一个或几个。CM和CM-CU都没有低估误差。更多的sketch在调查中详细介绍[15]。
与我们的Cold Filter最相关的工作是增强型sketch [5]。它向现有的sketchΦ添加一个额外的过滤器（一个包含k个项和计数器的队列），以在此过滤器中维护最频繁的项。当插入项e时，它逐一扫描存储在过滤器中的项。如果e已经在过滤器中，则只需增加其相应的计数器。否则，如果过滤器中有可用空间，则将e存储，并将其计数器初始化为1。如果没有可用空间，即过滤器已满，则将此项插入到sketchΦ中。在插入过程中，如果sketchΦ报告的这个项的频率大于过滤器中与项e'相关联的最小值，则增强型sketch需要将项e'驱逐到sketchΦ中，并将项e插入到过滤器中。


# 3.Cold Filter元框架
我们采用标准的数据流模型，即收银机模型[33, 34]。给定一个完整的数据流S，包含E个项和N个不同项，其中N⩽E。S=(e1,e2,...,eE)，其中每个项ei∈U={eβ1,eβ2,...,eβN}。请注意，U中的项是不同的，而S中的项可能不同。让t为当前时间点，et为当前传入的项，St=(e1,e2,...,et)为当前子流。et在当前子流St中出现fet[1,t]次，在整个流S中出现fet[1,E]次。为了方便起见，我们使用fet[t]和fet[E]简称。
问题陈述：给定数据流S=(e1,e2,...,eE)和当前时间点t，当前子流是St=(e1,e2,...,et)。对于当前项et，如何准确快速地估计其当前频率fet[t]是否超过预定义的阈值T？
3.1
一种朴素的解决方案是将一个sketch Φ（例如Count-Min sketch、CM-CU sketch等）用作CF。具体来说，我们使用Φ从时间点1开始记录每个项的频率。对于每个传入的项，我们首先查询Φ，获得其估计的频率。然后，我们检查这个估计频率是否超过了阈值T。然而，这种解决方案在实际数据流中存在内存效率问题。假设T=1000。对于Φ，我们将其计数器大小设置为16，可以计算高达65535的频率。但在实际数据流中，大多数项具有低频率，无法“填满”它们被哈希到的计数器。因此，Φ的大多数计数器中的许多高阶位被浪费，这意味着内存效率低下和亚优秀的过滤性能。如果我们能够自动为冷项分配小计数器和热项分配大计数器，那么就可以充分利用分配的内存。这是我们提出的解决方案实现的目标。

3.2 提出的解决方案

如图2所示，我们的 Cold Filter（CF2）由两个层组成：低层 L1 和高层 L2。这两个层分别由 w1 和 w2 个计数器组成，并与 d1 和 d2 个哈希函数（h(.) 和 д(.)）关联。层 L1 和层 L2 中每个计数器的大小分别为 δ1 和 δ2 位。我们将阈值 T 分成两部分：T = T1 + T2（1 ≤ T1 ≤ 2δ1 −1，1 ≤ T2 ≤ 2δ2 −1）。CF 处理传入的项 et 的过程如算法1所示。具体而言，有两个过程：更新和报告。

CF 的更新过程：如算法 1 所示，我们使用 V1 和 V2 分别表示低层的 d1 个散列计数器和高层的 d2 个散列计数器中最小值。如果 V1 < T1，则 CF 会将低层最小散列计数器的值加一（见第 4 行）。请注意，如果有多个计数器的值相同且均为最小值，则所有这些计数器都应被增加。在更新过程中，d1 个散列计数器的值可能会不同。但是，只增加最小计数器的操作始终会缩小 d1 个散列计数器值的差异。如果这些 d1 个散列计数器中的一个或多个的值达到 T1，则所有后续增量将添加到其他计数器中。因此，最终状态是所有 d1 个散列计数器将同时达到 T1。我们将这种状态称为并发溢出状态。到达这种状态时（即 V1 = T1），CF 将借助高层记录该项目的信息。对于低层处于并发溢出状态的 d1 个散列计数器，我们提出了一种新策略：保持它们不变。这种策略使得不需要使用额外的标志来指示并发溢出状态，这对于对 CF 的后续查询操作至关重要。高层的更新过程类似于低层的更新过程：如果 V2 < T2，则 CF 将最小的散列计数器的值增加一（见第 11 行）。
对于当前项 $et$，如果它的哈希计数器在低层同时溢出，则必须有 $f_{et}[t-1] \leq V_1/3$；如果其哈希计数器在低层同时溢出但没有在高层溢出，则 $f_{et}[t-1] \leq V_1 + V_2$。这是因为过去的每个项 $et$ 在更新前，如果 $V_1 < T_1$ 或者 $V_1 = T_1 \land V_2 < T_2$，则会将 $V_1 + V_2$ 的值增加一。事实上，$V_1$ 或 $V_1 + V_2$ 与 $f_{et}[t-1]$ 之间的潜在差距来自该项与第一层或第二层其他项之间的哈希碰撞。

CF 的报告过程：简而言之，如果哈希计数器在更新前同时溢出了两层，则 CF 报告 fet [t]>T；否则，CF 报告 fet [t]≤T。注意，fet [t]=fet [t-1]+1。
我们正式阐述报告过程如下：
(1) 如果 V1 <T1（算法1中的第2行），则有：fet [t-1]≤V1 <T1 <T。因此，我们报告 fet [t]≤T。
(2) 如果 V1 =T1 但 V2 <T2（第8行），则有：fet [t-1]≤V1 +V2 <T1 +T2=T。因此，我们也报告 fet [t]≤T。
(3) 如果 V1 =T1 且 V2 =T2（第13行），则有两种情况：
(a) fet [t-1]≥T，因此 fet [t] 肯定超过 T。我们应该报告 fet [t]>T。
(b) fet [t-1] <T，但哈希冲突导致 V1 =T1 和 V2 =T2。我们应该报告 fet [t]≤T。
不幸的是，区分这两种情况并不容易。为了获得空间和时间效率的好处，我们选择只报告 fet [t]>T。

本例中，我们设置d1 = d2 = 3，δ1 = δ2 = 4，T1 = T2 = 15。对于输入项et：1）如果其在层L1的三个哈希计数器为15、15、13，则V1 = min {15、15、13} = 13。然后，我们通过在L1层上增加第三个哈希计数器的值1来报告fet [t]≤T。2）如果它在层L1的三个哈希计数器为15、15、15（蓝色部分），则V1 = min {15、15、15} = 15 = T1。然后，我们需要访问层L2。假设其在层L2的三个哈希计数器为15、15、15，则V2 = min {15、15、15} = 15 = T2。然后，我们需要报告fet [t]>T。

此解决方案不会产生假负结果，仅会产生少量的假正结果。如果fet [t]确实超过了阈值T，CF将肯定识别这个超额（没有假负）。对于那些频率fet [t]不超过阈值T的项，CF可能会得出错误的结论（假正结果）。

在这里，我们使用一个数值例子进一步说明我们提出的两层CF相对于简单解决方案的优势。假设T = 1000。对于简单解决方案中的Φ，我们将其计数器大小设置为16位。回想一下，w表示Φ中计数器的数量。对于我们提出的两层CF，我们设置δ1 = 4，δ2 = 16，T1 = 15，T2 = 985。我们将50％的内存分配给L1层，50％的内存分配给L2层。显然，两层CF的w1是Φ的两倍。因此，在L1层，两层CF可以实现更低的哈希冲突，从而少量的冷门项将被错误报告。由于每个项访问L2层的平均概率非常低（当δ1 = 4时，通常少于实际数据流中的1/20），因此L2层仍然具有较低级别的哈希冲突。关于层数选择的进一步实验见…





# 7.结论
本文提出了一个名为Cold Filter的元框架，以增强现有的近似数据流处理算法。我们的元框架适用于各种数据流处理任务，可以同时提高准确性和速度。我们还介绍了如何将其部署在包括估计项频率、查找top-k热门项和检测重要更改等三个关键数据流处理任务上。实验结果表明，与现有解决方案相比，它显着提高了它们的处理速度和准确性。我们的Cold Filter元框架可以应用于更多的近似数据流处理任务，例如项频率分布、重要信息查找、信息熵等，并改善其性能。所有源代码都在Github [1]上发布。